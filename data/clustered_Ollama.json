[
    {
        "handle": "@DJohnstonEC\n·\nDec 2",
        "text": "Awesome to see other open source builders who use \n@ollama\n at NeurIPS! \n\nPart of the \n@MorpheusAIs\n origin story with the original local install.",
        "timestamp": "2025-12-18T12:05:23.832731",
        "x": 11.849430084228516,
        "y": 5.231146812438965,
        "sentiment": "positive",
        "sentiment_score": 0.959,
        "emotion": "joy",
        "emotion_score": 0.426,
        "cluster": 2
    },
    {
        "handle": "@BraveNightly\n·\nDec 8",
        "text": "Sync your \n@ollama\n local models!",
        "timestamp": "2025-12-18T12:05:23.851898",
        "x": 11.847039222717285,
        "y": 6.976156711578369,
        "sentiment": "positive",
        "sentiment_score": 0.278,
        "emotion": "neutral",
        "emotion_score": 0.653,
        "cluster": 2
    },
    {
        "handle": "@mim_djo\n·\nDec 5",
        "text": "Microsoft is officially joining the local LLM trend with Foundry Local. more or less the same as ollama or LM studio\nnow you finally have a solid business reason to ask for a better laptop :)\n\n#LLMs #AI #opensource \n\nhttps://\ngithub.com/microsoft/Foun\ndry-Local\n…",
        "timestamp": "2025-12-18T12:05:23.870633",
        "x": 12.37946891784668,
        "y": 4.670409202575684,
        "sentiment": "positive",
        "sentiment_score": 0.84,
        "emotion": "fear",
        "emotion_score": 0.711,
        "cluster": 2
    },
    {
        "handle": "@ollama\n·\nDec 9",
        "text": ".\n@essential_ai\n's rnj-1 model is now on Ollama!\n\nollama run rnj-1 \n\n8B parameter, open-weight dense model trained from scratch. The model is optimized for code and STEM with capabilities on par with other state of the art open-weight models. \n\nLet's go! ",
        "timestamp": "2025-12-18T12:05:23.890516",
        "x": 13.118928909301758,
        "y": 6.25046968460083,
        "sentiment": "positive",
        "sentiment_score": 0.581,
        "emotion": "fear",
        "emotion_score": 0.343,
        "cluster": 2
    },
    {
        "handle": "@zuri_nft\n·\n9h",
        "text": "Excited to try Gemini 3 Flash",
        "timestamp": "2025-12-18T12:05:25.816248",
        "x": 13.130071640014648,
        "y": 5.304206371307373,
        "sentiment": "positive",
        "sentiment_score": 0.979,
        "emotion": "joy",
        "emotion_score": 0.675,
        "cluster": 2
    },
    {
        "handle": "@tom_doerr\n·\nDec 5",
        "text": "GUI for batch processing text files with Ollama\n\n\nhttps://\ngithub.com/hclivess/ollam\na-batch-processor/\n…",
        "timestamp": "2025-12-18T12:05:25.837223",
        "x": 11.2628755569458,
        "y": 5.87253999710083,
        "sentiment": "positive",
        "sentiment_score": 0.118,
        "emotion": "neutral",
        "emotion_score": 0.872,
        "cluster": 2
    },
    {
        "handle": "@piacere_ex\n·\nDec 16",
        "text": "Using the same technique as running Phoenix on Android, I managed to get Ollama + Gemma3 running too lol\n\nMessing around with local LLMs is getting so much more fun, huh?",
        "timestamp": "2025-12-18T12:05:25.856385",
        "x": 12.42216682434082,
        "y": 5.6468424797058105,
        "sentiment": "positive",
        "sentiment_score": 0.9,
        "emotion": "joy",
        "emotion_score": 0.832,
        "cluster": 2
    },
    {
        "handle": "@BlackEnokas\n·\nDec 9",
        "text": "Please fix your billing system \n@ollama\n , why is he still trying to charge me after 2 months and i'm unable to cancel and remove my card",
        "timestamp": "2025-12-18T12:05:28.736154",
        "x": 12.044637680053711,
        "y": 6.400584697723389,
        "sentiment": "negative",
        "sentiment_score": -0.884,
        "emotion": "surprise",
        "emotion_score": 0.624,
        "cluster": 0
    },
    {
        "handle": "@PromptInjection\n·\n21h",
        "text": "Is there any documentation available that specifies the exact usage limits?",
        "timestamp": "2025-12-18T12:05:31.877131",
        "x": 10.802903175354004,
        "y": 5.1444411277771,
        "sentiment": "neutral",
        "sentiment_score": -0.082,
        "emotion": "neutral",
        "emotion_score": 0.953,
        "cluster": 1
    },
    {
        "handle": "@ollama\n·\nDec 16",
        "text": "Olmo 3.1 and 3 from \n@allen_ai\n models are available on Ollama. \n\n7B Instruct: \nollama run olmo-3:7b-instruct\n\n7B Think: \nollama run olmo-3:7b-think \n\n32B Instruct: \nollama run olmo-3.1:32b-instruct\n\n32B Think: \nollama run olmo-3.1:32b-think",
        "timestamp": "2025-12-18T12:05:31.894252",
        "x": 11.297869682312012,
        "y": 4.669426918029785,
        "sentiment": "positive",
        "sentiment_score": 0.154,
        "emotion": "neutral",
        "emotion_score": 0.588,
        "cluster": 2
    },
    {
        "handle": "@ollama\n·\n21h",
        "text": "Model page:",
        "timestamp": "2025-12-18T12:05:31.911811",
        "x": 12.83541202545166,
        "y": 7.0152692794799805,
        "sentiment": "neutral",
        "sentiment_score": 0.034,
        "emotion": "neutral",
        "emotion_score": 0.918,
        "cluster": 1
    }
]