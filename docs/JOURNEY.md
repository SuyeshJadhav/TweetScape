# üìî The TweetScape Builder's Diary

*A zigzag journey from a simple scraper to an autonomous semantic intelligence engine.*

---

## 1. The Spark (How it Started) ‚ö°

It started with a simple, slightly boring goal: **I just wanted to scrape some tweets.**

I was staring at a terminal full of JSON output‚Äîjust endless lines of text, timestamps, and unstructured noise. I tried reading them, but after the 50th tweet, my eyes glazed over. I realized that a list of tweets isn't *info*; it's just data.

I didn't want to just *read* the discourse; I wanted to **see** it.

I grabbed a notebook and sketched a crazy idea: What if tweets weren't just text? What if they were particles in a physics simulation? What if I could see the "shape" of an argument?

That was the spark. I closed the terminal and opened my code editor with a new mission: turn this wall of text into a living map.

## 2. "Wait, This Isn't Working" (The Pivots) üîÑ

The road wasn't straight. It was a series of "Oh no," followed by "Aha!"

### The Sentiment Fail
I started with **TextBlob** because it was easy. Big mistake.
I fed it a tweet: *"This beat is sick! üî•"*
TextBlob: *Negative (Sentiment: -0.7)*. üìâ

It thought slang was an insult! I realized binary sentiment (Good/Bad) was too basic for human convos.
**The Pivot:** I ripped out TextBlob and brought in **RoBERTa**. Suddenly, the app wasn't just seeing "Bad"; it was seeing **Anger**, **Disgust**, and **Fear**. It was seeing *nuance*.

### The Blobby Map
I initialized **t-SNE** to cluster the tweets. I expected beautiful islands of distinct topics.
Reality: A messy, shapeless blob. Everything was overlapping.
**The Pivot:** I switched to **UMAP**. It was like putting on glasses. Suddenly, the "Pricing" complaints separated from the "UX" complaints. The global structure held together. The map made sense.

### The Lazy Engineer
I got tired of manually searching for topics like "iPhone 16 battery" then "iPhone 16 camera" then "iPhone 16 screen".
I thought, *"I have an AI model right here... why am I doing the typing?"*
**The Pivot:** I integrated **Gemma 3 (via Ollama)** and built an **Investigator Agent**. Now, I just type "iPhone 16", and the Agent thinks: *"Okay, I should also look for heating issues, zoom tests, and price vs value."* It does the legwork for me.

## 3. The Messy Parts (Real Struggles) üõ†Ô∏è

Let's be real‚Äîit wasn't all smooth sailing.

### The "Demo Mode" Savior
Twitter/X has aggressive rate limits. During one of my first big demos, the scraper hit a login wall and crashed. Dead silence in the room.
**The Fix:** I built a robust cookie management system (the `cookies.json` file you see in the backend) and a fallback mechanism. If the live scrape fails, it degrades gracefully. It taught me that *resilience* is just as important as *intelligence*.

### The RAM Panic ü§Ø
I got greedy. I loaded KeyBERT, RoBERTa, and a Sentence Transformer all at once. My local server choked. RAM usage spiked to 98%, and my fan sounded like a jet engine.
**The Fix:** I had to get smart about resource sharing. I realized KeyBERT and UMAP could share the same underlying embedding model (`all-MiniLM-L6-v2`) instead of loading two giant models. We shaved off gigabytes of RAM usage with that one optimization.

### The Negative News Paradox (The Karnataka Case)
I was testing with news about a political event in Karnataka. The model flagged every single news report as "Hate Speech" or "Extreme Negativity."
Why? Because the news was reporting on *conflict*.
It was a humbling moment. The model couldn't distinguish between *reporting on bad things* and *saying bad things*. It taught me that data is context-dependent, and "Sentiment" isn't truth‚Äîit's just a signal that needs interpretation.

## 4. The Final Build (Why I'm Proud) üöÄ

I looked at the architecture diagram today and smiled.

It‚Äôs not just a script anymore. It‚Äôs a **System**:
*   **FastAPI** handles the heavy lifting.
*   **React + D3** makes the math beautiful.
*   **Ollama + Gemma 3** gives it a brain.
*   And I built my own **custom Agent loop** (no heavy frameworks needed!) to orchestrate it all.

I learned that "Full Stack AI" isn't just about chaining API calls. It's about engineering the flow of information‚Äîfrom raw, noisy text, through the lens of psychological models, into a visual story that a human can understand in seconds.

I built TweetScape to make sense of the noise. And along the way, I made sense of how to build AI products.
